{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Network Analysis - Python Handson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from networkx import nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The data set is provided by Der Standard, one of the top Austrian newspapers.\n",
    "In the online Standard people can post comments below articles and up/down vote comments.\n",
    "The data set used in this handson and further in the project part of the course will consider a sample of those articles, comments, and votes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sample_Articles_Int_081116_091116_Postings.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different entities in the data set: \n",
    "* Users - identified by *ID_CommunityIdentity* (or *UserCommunityName*)\n",
    "* Postings - identified by *ID_Posting*\n",
    "* Articles - identified by *ID_Article*\n",
    "\n",
    "Thus, there are different possibilities to build networks based on the posting data. \n",
    "We will concentrate now on the ***reply-to-network***. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = pd.read_csv('Sample_Articles_Int_081116_091116_Votes.csv', sep=';')\n",
    "votes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reply-To-Network\n",
    "\n",
    "The two fundamental components of a network are *nodes* and *edges*. \n",
    "In the anticipated reply-to-network nodes are the users (i.e., *ID_CommunityIdentity*). \n",
    "Edges between two nodes (i.e., users) are build if one user replys to a posting of another users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"ID_CommunityIdentity\", \"ID_Posting\", \"ID_Posting_Parent\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line in the table above shows that a user (i.e., *ID_CommunityIdentiy*) posted a comment. Every post has its own uniqe identifier (i.e., *ID_Posting*). If a user replys to a previous posting then the posting they are targeting is identified by *ID_Posting_Parent*. *NaN* shows that the posted comment is located in the root (i.e., it's not targeted towards any other comment). \n",
    "\n",
    "We want to bring the structure above into following format: \n",
    "* source, i.e., the replying user\n",
    "* target, i.e., the targeted user\n",
    "* weight, i.e., how often the source replied to the target\n",
    "\n",
    "In other words, we are aiming for a *weighted edge-list*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeList = [\n",
    "    [post.ID_CommunityIdentity, next(iter(df[df.ID_Posting == post.ID_Posting_Parent].ID_CommunityIdentity))] \n",
    "    for idx, post in df.iterrows()\n",
    "    if ~np.isnan(post.ID_Posting_Parent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeList[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedEdgeList = [(edge[0],edge[1],edgeList.count(edge)) for edge in edgeList]\n",
    "weightedEdgeList = list(set(weightedEdgeList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedEdgeList[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.DataFrame(weightedEdgeList, columns=['source','target','weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.to_csv(\"reply_to_edges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph\n",
    "\n",
    "We use the *networkx* library.\n",
    "Since we build a *reply-to-network* we have *source* nodes and *target* nodes. \n",
    "Thus, the network is directed.\n",
    "Therefore, we use *nx.Digraph()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(edges, \n",
    "                            source='source', \n",
    "                            target='target', \n",
    "                            edge_attr = 'weight',\n",
    "                            create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50,50))\n",
    "nx.draw_spring(G)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of edges with weight 1\n",
    "len(edges[edges.weight == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max weight of edges\n",
    "edges.weight.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average weight \n",
    "edges.weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network density and path lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network density\n",
    "nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average distance (i.e. average shortest path length)\n",
    "nx.average_shortest_path_length(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method average_shortest_path_length throws an exception if the underlying Graph is disconnected. Thus, one can calculate the average of all finite distances (i.e., existing shortest pathes) nx.single_source_shortest_path_length(G, N) delivers the length of all shortest pathes beginning from node N. Furthermore, the first shortest path is always the distance to itself (i.e., zero), which as to be filtered later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute all distances\n",
    "distances = [list(nx.single_source_shortest_path_length(G,N).values()) for N in G.nodes]\n",
    "# Flatten the distances list! Currently list of lists of single node distances\n",
    "# and filter out the unnecessary zeroes\n",
    "distances = [distance for single_distances in distances for distance in single_distances if distance > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average\n",
    "np.mean(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To consider the weight one can use e.g. nx.single_source_dijkstra_path_length() But watch out, what does weight in our case mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diameter (i.e, longest shortest path)\n",
    "np.max(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G.subgraph(c) for c in nx.weakly_connected_components(G) delivers a Generator,which can be used to iterate over all weakly connected compontents (deliverd as a subgraph for further analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wccs = [c for c in (G.subgraph(c) for c in nx.weakly_connected_components(G))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of wccs\n",
    "len(wccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of wccs\n",
    "nx.number_weakly_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sizes of the wccs:\n",
    "\n",
    "nx.number_of_nodes() delivers the number of nodes of a graph. This can be done for all weakly connected components wcc in the weakly connected component list. Furthermore, with set() one can get the uniqe values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([nx.number_of_nodes(wcc) for wcc in wccs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not the uniqe values are in focus, but the for example how often a wcc with n Nodes appear, one can use Counter().most_common() as follwing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter([nx.number_of_nodes(wcc) for wcc in wccs]).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strongly connected components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sccs = [c for c in (G.subgraph(c) for c in nx.strongly_connected_components(G))]\n",
    "Counter([nx.number_of_nodes(scc) for scc in sccs]).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local**\n",
    "\n",
    "nx.clustering(G) returns back a dictionary with clustering coefficients of each node.\n",
    "with the combination of sorted() and itemgetter() one can get a sorted list of (ID,clustering coeff.) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "sorted(nx.clustering(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"*the clustering coefficient quantifies how close the neighbours of i are to being a clique.*\" (lecture slides) i.e., how concentrated the neighbours of a nodes is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global**\n",
    "\n",
    "The global clustering coefficient can have alternative definitions:\n",
    "\n",
    "1) as the average of the local clustering coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that there might be differences if you use other tools (e.g., Gephi, Igraph, etc.).\n",
    "So, why does networkx delivers a different average clustering coefficiet?\n",
    "In order to find an answer, take a look at the nx.clustering() documentation (since nx.average_clustering is just averaging over the individual values). https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.cluster.clustering.html\n",
    "It says, that clustering coefficients for nodes with degrees lower than 2 is set to ZERO.\n",
    "\n",
    "Thus, there is no right or wrong way of implementation, but you have to be aware what you are using.\n",
    "\n",
    "2) as the ratio of triangles and connected triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.transitivity(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-Degree**\n",
    "\n",
    "[nx.in_degree_centrality(G)](https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.in_degree_centrality.html#networkx.algorithms.centrality.in_degree_centrality) delivers in-degree-centrality of each node in a graph G.\n",
    "Note, that the centralities are normalized.\n",
    "\n",
    "\n",
    "With a combination of sorted() and itemgetter() one can again get a sorted list of (Node, centrality) tuples.\n",
    "Where one can just take the first 5 for reporting.\n",
    "Note, reverse=True means in decreasing order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.in_degree_centrality(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User *588542* is replied the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out-Degree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.out_degree_centrality(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User *588542* also replies the most"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eigenvector-Centrality**\n",
    "\n",
    "Eigenvector centrality computes the centrality for a node based on the centrality of its neighbors. The eigenvector centrality for node i is the i-th element of the vector ğ‘¥ defined by the equation\n",
    "\n",
    "ğ´ğ‘¥=ğœ†ğ‘¥\n",
    "\n",
    "where ğ´ is the adjacency matrix of the graph G with eigenvalue ğœ†. By virtue of the Perronâ€“Frobenius theorem, there is a unique solution ğ‘¥, all of whose entries are positive, if ğœ† is the largest eigenvalue of the adjacency matrix ğ´\n",
    "A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.eigenvector_centrality(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-closeness centrality**\n",
    "\n",
    "Closeness centrality of a node u is the reciprocal of the average shortest path distance to u over all n-1 reachable nodes.\n",
    "\n",
    "ğ¶(ğ‘¢)= (ğ‘›âˆ’1)/âˆ‘ğ‘‘(ğ‘£,ğ‘¢)\n",
    "\n",
    "where d(v, u) is the shortest-path distance between v and u, and n is the number of nodes that can reach u. Notice that the closeness distance function computes the incoming distance to u for directed graphs. To use outward distance, act on G.reverse()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.closeness_centrality(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out-closeness centrality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.closeness_centrality(G.reverse()).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Betweeness centrality**\n",
    "\n",
    "Betweenness centrality of a node ğ‘£ is the sum of the fraction of all-pairs shortest paths that pass through ğ‘£\n",
    "\n",
    "ğ‘ğµ(ğ‘£)=âˆ‘ğœ(ğ‘ ,ğ‘¡|ğ‘£)/ğœ(ğ‘ ,ğ‘¡)\n",
    "\n",
    "where, ğœ(ğ‘ ,ğ‘¡) is the number of shortest (ğ‘ ,ğ‘¡)-paths, and ğœ(ğ‘ ,ğ‘¡|ğ‘£) is the number of those paths passing through some node ğ‘£ other than ğ‘ ,ğ‘¡ .\n",
    "\n",
    "\n",
    "Using k=100 nodes to estimate the betweeness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.betweenness_centrality(G, k=100).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hubs and Authorities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs_auth = nx.hits(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hub scores\n",
    "sorted(hubs_auth[0].items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authority scores\n",
    "sorted(hubs_auth[1].items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Page Rank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(nx.pagerank(G).items(), key=itemgetter(1), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
