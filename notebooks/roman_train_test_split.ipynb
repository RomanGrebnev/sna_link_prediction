{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typing import Dict\n",
    "\n",
    "from torch import nn, optim, Tensor, torch\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader.data_loader import UserUserDataset\n",
    "from light_gcn.light_gcn import LightGCN, bpr_loss, get_user_positive_items, RecallPrecision_ATk, NDCGatK_r, get_metrics, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1+cu118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "postings_1 = pd.read_csv(\"../data/Postings_01052019_15052019.csv\", sep = ';')\n",
    "postings_2 = pd.read_csv(\"../data/Postings_16052019_31052019.csv\", sep = ';')\n",
    "votes_1 = pd.read_csv(\"../data/Votes_01052019_15052019.csv\", sep = ';')\n",
    "votes_2 = pd.read_csv(\"../data/Votes_16052019_31052019.csv\", sep = ';')\n",
    "postings = pd.concat([postings_1, postings_2])\n",
    "votes = pd.concat([votes_1, votes_2])\n",
    "\n",
    "datasets_dict = {\n",
    "    \"postings\": postings,\n",
    "    \"votes\": votes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu_dataset = UserUserDataset(datasets_dict = datasets_dict, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_index, val_edge_index, test_edge_index = uu_dataset.get_train_test_val_split(val_split_ratio = 0.2, test_split_ratio = 0.5, random_state = 1, sparse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target, negative_target = uu_dataset.get_negative_samples(train_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_indices, pos_item_indices, neg_item_indices = uu_dataset.get_random_mini_batches(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users, num_articles = uu_dataset.num_users, uu_dataset.num_articles\n",
    "model = LightGCN(num_users, num_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 512\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 1000\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 100\n",
    "LAMBDA = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device_name = 'cpu'\n",
    "device = torch.device(device_name)\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "edge_index = uu_dataset.edge_index.to(device)\n",
    "\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_sparse_edge_index = uu_dataset.train_sparse_edge_index.to(device)\n",
    "\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "val_sparse_edge_index = uu_dataset.val_sparse_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/10000 [03:33<153:43:52, 55.36s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/10000] train_loss: -0.69219, val_loss: -0.48347, val_recall@100: 0.01776, val_precision@100: 0.00091, val_ndcg@100: 0.00562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 999/10000 [04:41<10:01, 14.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1003/10000 [08:05<53:33:13, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1000/10000] train_loss: -44.31754, val_loss: -3.8935, val_recall@100: 0.2042, val_precision@100: 0.0099, val_ndcg@100: 0.07721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1999/10000 [09:13<09:29, 14.05it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2003/10000 [12:37<47:46:52, 21.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 2000/10000] train_loss: -118.54932, val_loss: -11.38222, val_recall@100: 0.2121, val_precision@100: 0.01, val_ndcg@100: 0.08028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2999/10000 [13:46<08:33, 13.64it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3003/10000 [17:11<41:50:33, 21.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 3000/10000] train_loss: -195.56348, val_loss: -18.76358, val_recall@100: 0.21428, val_precision@100: 0.01003, val_ndcg@100: 0.08089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3999/10000 [18:20<07:05, 14.09it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4003/10000 [21:45<35:58:44, 21.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 4000/10000] train_loss: -271.21112, val_loss: -25.38278, val_recall@100: 0.21547, val_precision@100: 0.01005, val_ndcg@100: 0.08119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4999/10000 [22:54<06:09, 13.54it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5003/10000 [26:16<29:31:19, 21.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 5000/10000] train_loss: -304.68597, val_loss: -30.89661, val_recall@100: 0.21658, val_precision@100: 0.01006, val_ndcg@100: 0.08145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5999/10000 [27:25<04:48, 13.85it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6003/10000 [30:46<23:30:28, 21.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 6000/10000] train_loss: -355.63431, val_loss: -35.38113, val_recall@100: 0.2166, val_precision@100: 0.01006, val_ndcg@100: 0.08153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6999/10000 [31:54<03:40, 13.60it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7003/10000 [35:19<17:56:15, 21.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 7000/10000] train_loss: -399.13916, val_loss: -38.83504, val_recall@100: 0.21684, val_precision@100: 0.01007, val_ndcg@100: 0.08154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 7999/10000 [36:27<02:17, 14.59it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8003/10000 [39:49<11:49:13, 21.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 8000/10000] train_loss: -457.30225, val_loss: -41.64065, val_recall@100: 0.21689, val_precision@100: 0.01007, val_ndcg@100: 0.08161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 8999/10000 [40:56<01:08, 14.53it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9003/10000 [44:17<5:51:19, 21.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 9000/10000] train_loss: -446.88718, val_loss: -43.8705, val_recall@100: 0.21698, val_precision@100: 0.01007, val_ndcg@100: 0.08166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [45:24<00:00,  3.67it/s] \n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iter in tqdm(range(ITERATIONS)):\n",
    "\n",
    "    # forward propagation\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(train_sparse_edge_index)\n",
    "\n",
    "    # mini batching\n",
    "    user_indices, pos_item_indices, neg_item_indices = uu_dataset.get_random_mini_batches(BATCH_SIZE)\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
    "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, precision, ndcg = evaluation(\n",
    "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
    "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        model.train()\n",
    "\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sna_link_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
